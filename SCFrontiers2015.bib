%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for kmorel at 2015-03-10 17:34:45 -0600 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{Maynard2013,
	Abstract = {As the HPC community starts focusing its efforts towards exascale, it becomes clear that we are looking at machines with a billion way concurrency. Although parallel computing has been at the core of the performance gains achieved until now, scaling over 1,000 times the current concurrency can be challenging. As discussed in this paper, even the smallest memory access and synchronization overheads can cause major bottlenecks at this scale. As we develop new software and adapt existing algorithms for exascale, we need to be cognizant of such pitfalls. In this paper, we document our experience with optimizing a fairly common and parallelizable visualization algorithm, threshold of cells based on scalar values, for such highly concurrent architectures. Our experiments help us identify design patterns that can be generalized for other visualization algorithms as well. We discuss our implementation within the Dax toolkit, which is a framework for data analysis and visualization at extreme scale. The Dax toolkit employs the patterns discussed here within the framework's scaffolding to make it easier for algorithm developers to write algorithms without having to worry about such scaling issues.},
	Annote = {A reporting on some of the optimizations we did for threshold in Dax.},
	Author = {Robert Maynard and Kenneth Moreland and Utkarsh Ayachit and Berk Geveci and Kwan-Liu Ma},
	Booktitle = {Visualization and Data Analysis 2013, Proceedings of SPIE-IS\&T Electronic Imaging},
	Date-Added = {2015-03-10 23:24:57 +0000},
	Date-Modified = {2015-03-10 23:24:57 +0000},
	Month = {February},
	Note = {{DOI}~10.1117/12.2007320},
	Title = {Optimizing Threshold for Extreme Scale Analysis},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1117/12.2007320}}

@misc{Bell2010,
	Annote = {A presentation containing several example programs in thrust.  One important one for us (and does not have a lot of other examples) is an implementation of vertex-weld.},
	Author = {Bell, Nathan},
	Booktitle = {GPU Technology Conference},
	Date-Added = {2015-03-10 22:52:49 +0000},
	Date-Modified = {2015-03-10 22:52:49 +0000},
	File = {:home/bob/Desktop/Old Ubuntu FS/home/bob/Papers/GPUCoincidentPoints/References/GTC 2010 (Part 1) - High Productivity Development.pdf:pdf},
	Title = {High-Productivity {CUDA} Development with the Thrust Template Library},
	Year = {2010}}

@inproceedings{Miller2014,
	Abstract = {Graphics and visualization pipelines often make use of highly parallelized algorithms which transform an input mesh into an output mesh. One example is Marching Cubes, which transforms a voxel grid into a triangle mesh approximation of an isosurface. These techniques often discard the topological connectivity of the output mesh, and instead produce a 'soup' of disconnected geometric elements. Calculations that require local neighborhood, such as surface curvature, cannot be performed on such outputs without first reconstructing its topology. We present a novel method for reconstructing topological information across several kinds of mesh transformations, which we demonstrate with GPU and OpenMP implementations. Our approach makes use of input topological elements for efficient location of coincident elements in the output. We provide performance data for the technique for isosurface generation, tetrahedralization, subdivision, and dual mesh generation, and demonstrate its use in visualization pipelines containing further computations of local curvature and mesh coarsening.},
	Annote = {A general pattern to join coincident components created independently by finely decomposed threads. The technique is demonstrated with marching cubes, cell subdivision, and face-centered tetrahedralization. The paper also demonstrates a coarsening technique for marching cubes for free.},
	Author = {Robert Miller and Kenneth Moreland and Kwan-Liu Ma},
	Booktitle = {Eurographics Symposium on Parallel Graphics and Visualization},
	Date-Added = {2015-03-10 22:15:02 +0000},
	Date-Modified = {2015-03-10 22:15:02 +0000},
	Note = {{DOI}~10.2312/pgv.20141083},
	Title = {Finely-Threaded History-Based Topology Computation},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.2312/pgv.20141083},
	Bdsk-Url-2 = {http://www.sandia.gov/~kmorel/documents/TopologyThreading.pdf}}

@inproceedings{PISTON,
    author =    "Lo, Li-ta and Sewell, Christopher and Ahrens, James",
    title =     "{PISTON}: A Portable Cross-Platform Framework for Data-Parallel
 Visualization Operators",
    publisher = "Eurographics Symposium on Parallel Graphics and Visualization",
    year =      "2012",
    pages = {11-20},
    numpages =  "10",
}


@inproceedings{Moreland2013:UltraVis,
	Abstract = {As the number of cores in processors increase and accelerator architectures
are becoming more common, an ever greater number of threads is required to
achieve full processor utilization. Our current parallel scientific
visualization codes rely on partitioning data to achieve parallel
processing, but this approach will not scale as we approach massive
threading in which work is distributed in such a fine level that each
thread is responsible for a minute portion of data. In this paper we
characterize the challenges of refactoring our current visualization
algorithms by considering the finest portion of work each performs and
examining the domain of input data, overlaps of output domains, and
interdependencies among work instances. We divide our visualization
algorithms into eight categories, each containing algorithms with the same
interdependencies. By focusing our research efforts to solving these
categorial challenges rather than this legion of individual algorithms, we
can make attainable advancement for extreme computing.
},
	Annote = {Classifies all (well, most) of the filters in ParaView into catagories based on how they break up data, how they map input to output, and what collective work is done. This paper is meant to serve a basis for the worklet types implemented in Dax.},
	Author = {Kenneth Moreland and Berk Geveci and Kwan-Liu Ma and Robert Maynard},
	Booktitle = {Proceedings of Ultrascale Visualization Workshop},
	Date-Added = {2015-03-10 20:02:44 +0000},
	Date-Modified = {2015-03-10 20:02:44 +0000},
	Month = {November},
	Note = {{DOI}~10.1145/2535571.2535591},
	Title = {A Classification of Scientific Visualization Algorithms for Massive Threading},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2535571.2535591}}

@article{Stratton2012,
	Abstract = {A study of the implementation patterns among massively threaded applications for many-core GPUs reveals that each of the seven most commonly used algorithm and data optimization techniques can enhance the performance of applicable kernels by 2 to 10Ã— in current processors while also improving future scalability.},
	Annote = {A high level article that covers some general techniques on making massively threaded algorithms more efficient.  Techniques include: using structures of arrays (SoA) instead of arrays of structures (AoS), using gathers instead of scatters, group data in small units that fit on cache (tiling), assigning output entries to single threads (privatization), map from output locations to subset of input that effects it (binning), determining the compact layout of an output array when needs of threads is unknown (compaction), and statically balance workload among threads (regularization).},
	Author = {John A. Stratton and Christopher Rodrigues and I-Jui Sung and Li-Wen Chang and Nasser Anssari and Geng Liu and Wen-mei W. Hwu and Nady Obeid},
	Date-Added = {2015-03-10 20:02:25 +0000},
	Date-Modified = {2015-03-10 20:02:25 +0000},
	Journal = {IEEE Computer},
	Month = {August},
	Note = {{DOI}~10.1109/MC.2012.194},
	Number = {8},
	Pages = {26--32},
	Title = {Algorithm and Data Optimization Techniques for Scaling to Massively Threaded Systems},
	Volume = {48},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/MC.2012.194}}

@inproceedings{Sewell2012,
	Abstract = {This paper surveys the four software frameworks being developed as part of the visualization pillar of the SDAV (Scalable Data Management, Analysis, and Visualization) Institute, one of the SciDAC (Scientific Discovery through Advanced Computing) Institutes established by the ASCR (Advanced Scientific Computing Research) Program of the U.S. Department of Energy. These frameworks include EAVL (Extreme-scale Analysis and Visualization Library), DAX (Data Analysis at Extreme), DIY (Do It Yourself), and PISTON. The objective of these frameworks is to facilitate the adaptation of visualization and analysis algorithms to take advantage of the available parallelism in emerging multi-core and many-core hardware architectures, in anticipation of the need for such algorithms to be run in-situ with LCF (leadership-class facilities) simulation codes on supercomputers.},
	Annote = {Describes four frameworks addressing large-scale HPC visualization problems.  These are EAVL, Dax, DIY, and PISTON.
},
	Author = {Christopher Sewell and Jeremy Meredith and Kenneth Moreland and Tom Peterka and Dave DeMarle and Li-Ta Lo and James Ahrens and Robert Maynard and Berk Geveci},
	Booktitle = {2012 SC Companion (Proceedings of the Ultrascale Visualization Workshop)},
	Date-Added = {2015-02-12 23:24:37 +0000},
	Date-Modified = {2015-02-12 23:24:37 +0000},
	Month = {November},
	Note = {{DOI}~10.1109/SC.Companion.2012.36},
	Pages = {206--214},
	Title = {The {SDAV} Software Frameworks for Visualization and Analysis on Next-Generation Multi-Core and Many-Core Architectures},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/SC.Companion.2012.36}}

@book{TBB,
	Annote = {The user's guide and reference book for Intel Threading Building Blocks (TBB).  Also contains lots of practical advice on creating efficient application including notes on locking, allocations, cache-lines, and false-sharing.},
	Author = {James Reinders},
	Date-Added = {2015-02-12 23:21:21 +0000},
	Date-Modified = {2015-02-12 23:21:21 +0000},
	Month = {July},
	Note = {{ISBN}~978-0-596-51480-8},
	Publisher = {O'Reilly},
	Title = {Intel Threading Building Blocks: Outfitting {C++} for Multi-core Processor Parallelism},
	Year = {2007}}

@inbook{Thrust,
	Annote = {A portable STL-like template library for use on multi- and many-core systems.},
	Author = {Nathan Bell and Jared Hoberock},
	Chapter = {Thrust: A Productivity-Oriented Library for {CUDA}},
	Date-Added = {2015-02-12 23:21:12 +0000},
	Date-Modified = {2015-02-12 23:21:12 +0000},
	Month = {October},
	Pages = {359--371},
	Publisher = {Morgan Kaufmann},
	Title = {GPU Computing Gems, Jade Edition},
	Year = {2011}}

@inproceedings{Larsen:PacVis2015,
    author = {Matt Larsen and Jeremy Meredith and Paul Navr\'{a}til and Hank Childs},
    title = {{Ray-Tracing Within a Data Parallel Framework}},
    booktitle = {Proceedings of the IEEE Pacific Visualization Symposium},
    month=apr,
    year ={2015},
    address = {Hangzhou, China},
    note = "(to appear)"
}

@book{Blelloch1990,
	Abstract = {Vector Models for Data-Parallel Computing describes a model of parallelism that extends and formalizes the Data-Parallel model on which the Connection Machine and other supercomputers are based. It presents many algorithms based on the model, ranging from graph algorithms to numerical algorithms, and argues that data-parallel models are not only practical and can be applied to a surprisingly wide variety of problems, they are also well suited for very-high-level languages and lead to a concise and clear description of algorithms and their complexity. Many of the author's ideas have been incorporated into the instruction set and into algorithms currently running on the Connection Machine.

The book includes the definition of a parallel vector machine; an extensive description of the uses of the scan (also called parallel-prefix) operations; the introduction of segmented vector operations; parallel data structures for trees, graphs, and grids; many parallel computational-geometry, graph, numerical and sorting algorithms; techniques for compiling nested parallelism; a compiler for Paralation Lisp; and details on the implementation of the scan operations.},
	Annote = {Seminal work on using scans and other basic parallel algorithms to build more specific data-parallel algorithms.},
	Author = {Guy E. Blelloch},
	Date-Added = {2015-02-12 23:15:29 +0000},
	Date-Modified = {2015-02-12 23:15:29 +0000},
	Note = {{ISBN}~0-262-02313-X},
	Publisher = {MIT Press},
	Title = {Vector Models for Data-Parallel Computing},
	Year = {1990}}

@article{Childs2013,
	Abstract = {As the visualization research community reorients its software to address up-coming challenges, it must successfully deal with diverse processor architectures, distributed systems, various data sources, massive parallelism, multiple input and output devices, and interactivity.
},
	Annote = {This article gives a high level overview of the challenges of large-scale HPC visualization in the exascale/extreme scale from a technical standpoint.  The issues raised are: Massive Parallelization, Processor Architectures and Programming Models, Application Architecture and Data Management, Data Models, Rendering, and Interaction.},
	Author = {Hank Childs and Berk Geveci and Will Schroeder and Jeremy Meredith and Kenneth Moreland and Christopher Sewell and Torsten Kuhlen and E. Wes Bethel},
	Date-Added = {2015-02-12 22:45:19 +0000},
	Date-Modified = {2015-02-12 22:45:19 +0000},
	Journal = {IEEE Computer},
	Month = {May},
	Note = {{DOI}~10.1109/MC.2013.179},
	Number = {5},
	Pages = {34--42},
	Title = {Research Challenges for Visualization Software},
	Volume = {46},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/MC.2013.179}}

@book{ParaView,
	Annote = {Dude, its ParaView.},
	Author = {Utkarsh Ayachit},
	Date-Added = {2015-02-12 22:09:29 +0000},
	Date-Modified = {2015-02-12 22:09:29 +0000},
	Edition = {4.3},
	Month = {January},
	Note = {{ISBN} 978-1-930934-30-6},
	Publisher = {Kitware Inc.},
	Title = {The {ParaView} Guide: A Parallel Visualization Application},
	Year = {2015},
	Bdsk-Url-1 = {http://www.paraview.org}}


@inproceedings{DAX,
author = {Kenneth Moreland and Utkarsh Ayachit and Berk Geveci and Kwan-Liu Ma},
title = {{Dax Toolkit: A Proposed Framework for Data Analysis and Visualization at Extreme Scale}},
booktitle = {Proceedings of the IEEE Symposium on Large-Scale Data Analysis and Visualization},
month = {October},
pages = {97--104},
year = {2011}
}


@inproceedings{EAVL,
        title = {{EAVL:} The Extreme-scale Analysis and Visualization Library},
        isbn = {3905674351},
        booktitle = {Eurographics Symposium on Parallel Graphics and Visualization},
        publisher = {The Eurographics Association},
        author = {Meredith, J. S. and Ahern, S. and Pugmire, D. and Sisneros, R.},
        year = {2012},
        pages = {21--30}
}

@InCollection{VisIt,
  author = {Hank Childs and Eric Brugger and Brad Whitlock and Jeremy Meredith and Sean Ahern and David Pugmire and Kathleen Biagas and Mark Miller and Cyrus Harrison and Gunther H. Weber and Hari Krishnan and Thomas Fogal and Allen Sanderson and Christoph Garth and E. Wes Bethel and David Camp and Oliver R\"{u}bel and Marc Durant and Jean M. Favre  and Paul Navr\'{a}til},
  title = {{VisIt: An End-User Tool For Visualizing and Analyzing Very Large Data}},
   year =      "2012",
   pages = "357--372",
  month = oct,
  booktitle = {{High Performance Visualization---Enabling Extreme-Scale Scientific \linebreak Insight}},
}

@misc{ScientificDiscoveryExascale2011,
	Annote = {Workshop report on upcoming visualization challenges at exascale.  Big challenges include overcoming lower relative I/O rates through various more advanced I/O technologies such as in situ computations.  Also includes discussion on upcoming algorithmic challenges.},
	Author = {Sean Ahern and Arie Shoshani and Kwan-Liu Ma and others},
	Date-Added = {2015-02-12 21:22:17 +0000},
	Date-Modified = {2015-02-12 21:22:17 +0000},
	Howpublished = {Report from the DOE ASCR 2011 Workshop on Exascale Data Management, Analysis, and Visualization},
	Month = {February},
	Title = {Scientific Discovery at the Exascale},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sandia.gov/~kmorel/documents/Exascale-ASCR-Analysis.pdf}}

@techreport{ExascaleArchitecturesReport,
	Annote = {Another workshop report for predicting exascale computers and the necessary changes for it.},
	Author = {Rick Stevens and Andrew White and others},
	Date-Added = {2015-02-12 21:22:08 +0000},
	Date-Modified = {2015-02-12 21:22:08 +0000},
	Institution = {ASCR Scientific Grand Challenges Workshop Series},
	Month = {December},
	Title = {Architectures and Technology for Extreme Scale Computing},
	Year = {2009},
	Bdsk-Url-1 = {http://science.energy.gov/~/media/ascr/pdf/program-documents/docs/Arch_tech_grand_challenges_report.pdf}}


@inproceedings{parker2010optix,
  title={Optix: a general purpose ray tracing engine},
  author={Parker, Steven G and others},
  booktitle={ACM Transactions on Graphics (TOG)},
  volume={29},
  number={4},
  pages={66},
  year={2010},
  organization={ACM}
}

@article{wald2014embree,
  title={Embree: A Kernel Framework for Efficient CPU Ray Tracing},
  author={Wald, Ingo and Woop, Sven and Benthin, Carsten and Johnson, Gregory S and Ernst, Manfred},
  journal = {ACM Transactions on Graphics (proceedings of SIGGRAPH)},
  year={2014}
}

